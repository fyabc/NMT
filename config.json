{
    /// Basic config.
    // FIXME: The key names start with `GeneratedPrefix` (default is '__')
    // are reserved for generated options (worker_id, etc.), do not use these keys!

    /// Job name, must set it!
    "name": null,

    // Reload the previous saved config? Default is True.
    // If False, it will use current config and save it (will overwrite previous config)
    // If there is not any previous config, this config is useless: just load current config.
    "reload_config": true,

    // Float type.
    "floatX": "float32",
    // Random seed.
    "seed": 1234,

    // Logging filename.
    // directory is '${PROJECT_ROOT}/log/${job_name}/'
    "logging_file": "log.txt",

    // Append logging file or create a new logging file?
    "append": false,

    /// Train type, useless now
    // Candidates:
    //     baseline
    //     (More in future)
    "type": "baseline",

    // Reload model of ? iteration. Default is None.
    // If this is None, will load newest model, and this will be set to the iteration of this model.
    // If this <= 0, will restart the training, and old models will be overwritten.
    // If this > 0, will load the model of this iteration.
    "start_iteration": null,

    // Open Theano profile mode?
    "profile": false,

    // Discount learning rate after ? iterations
    "lr_discount_freq": 80000,

    /// Model structure config

    // Model type (unused now)
    "model": "Gru-FastFw",

    /// Model options (keywords in function ``train``)

    "dim_word": 100,        // Word vector dimensionality
    "dim": 1000,            // The number of LSTM units
    "alignment_dim": 512,

    "encoder": "multi_gru",
    "decoder": "gru_cond",

    "patience": 100,        // Early stopping patience
    "max_epochs": 5000,
    "finish_after": 10000000,   // Finish after this many updates

    "dispFreq": 100,

    "decay_c": 0.0,         // L2 regularization penalty
    "alpha_c": 0.0,         // Alignment regularization
    "clip_c": -1.0,         // Gradient clipping threshold
    "lrate": 0.01,          // Learning rate

    // Vocabulary size
    "n_words_src": 30000,
    "n_words": 30000,

    "maxlen": 1000,         // Maximum length of the description

    "optimizer": "rmsprop",

    "batch_size": 64,
    "valid_batch_size": 80,

    /// Model name
    // directory is '${PROJECT_ROOT}/model/${job_name}'
    "saveto": "model.npz",

    "validFreq": 10000,
    "saveFreq": 5000,       // Save the parameters after every saveFreq updates
    "sampleFreq": 100000,   // Generate some samples after every sampleFreq

    /// Data paths.
    // '~' means '${PROJECT_ROOT}/data'

    // Training data filenames
    "data_src": "~/train/filtered_en-fr.en",
    "data_tgt": "~/train/filtered_en-fr.fr",

    // Valid data filenames
    "valid_src": "~/valid/dev_en.tok",
    "valid_tgt": "~/valid/dev_fr.tok",

    // Vocabulary filenames
    "vocab_src": "~/dic/filtered_en-fr.en.pkl",
    "vocab_tgt": "~/dic/filtered_en-fr.fr.pkl",

    "use_dropout": [false],

    "reload_": false,
    "overwrite": false,

    // Number of layers in encoder/decoder
    "m_encoder_layer": 1,
    "m_decoder_layer": 1,

    "syncbatch": 1,

    "network_style": "GRUwithFastFw",

    "use_zigzag": true,
    "use_half": true,
    "use_theta": true,

    // Initialize distribution
    // Candidates: "normal", "uniform"
    "init_distr": "normal",
    "init_affine_weight": 0.01,

    // Other options
    "upload_emb": false
}
